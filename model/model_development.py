# -*- coding: utf-8 -*-
"""model-development.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15fDSZRKBV-SYw0ywJBvtloq46nsWVWCv
"""

'''
Name: model-development.(ipynb/py)
Description: Notebook for continuous model development, tweaking, and testing
Authors: Landen Doty, Sepehr Noori
Date: 11/5/23
'''


###check out [https://github.com/nicknochnack/RealTimeAutomaticNumberPlateRecognition/blob/main/Automatic%20Number%20Plate%20Detection.ipynb]##

"""# Import Packages"""

# Commented out IPython magic to ensure Python compatibility.
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

"""# Import Data from Drive"""

import os
import zipfile
# mounting local google drive
from google.colab import drive
drive.mount('/content/drive')

# copying local drive data to colab
!mkdir /tmp/data

"""# Binary Cars

Opening the zip file containing the image data
"""

# Unzip and store data on colab instance
!cp "/content/drive/MyDrive/Colab Notebooks/ParkSense/datasets/vehicle_detection_data.zip" "/tmp/data/"
zip_file = '/tmp/data/vehicle_detection_data.zip'
zip_ref = zipfile.ZipFile(zip_file, 'r')
zip_ref.extractall('/tmp/data/vehicle_data')
zip_ref.close()

"""Creating temporary folders to store data during colab runtime"""

# path to datasets
vehicle = '/tmp/data/vehicle_data/data/vehicles/'
non_vehicle = '/tmp/data/vehicle_data/data/non-vehicles/'

"""# Split Dataset into training and validation

This portion calls setup-data.sh which is a bash script that splits the vehicles and non-vehicles images into a training and a testing dataset. There is an even distribution of vehicle and non vehicle images in both datasets.
"""

! bash /content/drive/MyDrive/Colab\ Notebooks/ParkSense/setup-data.sh

! rm -r /tmp/data/vehicle_data/data/vehicles
! rm -r /tmp/data/vehicle_data/data/non-vehicles/

!cp "/content/drive/MyDrive/Colab Notebooks/ParkSense/datasets/stanford_car_data.zip" "/tmp/data/"
zip_file = '/tmp/data/stanford_car_data.zip'
zip_ref = zipfile.ZipFile(zip_file, 'r')
zip_ref.extractall("/tmp/data/stanford_cars")

"""# Data Generators

Tensorflow data generators help us normalize the image data to reduce input size of the model as well as split the images for training and validation.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Create training and validation data generators
# Currently normalizes images, but commented lines can be used for image augmentation if our model requires re-training with more creative datasets

# validation split allows us to use 25% of the specified dir. for training
train_datagen = ImageDataGenerator(
      rescale=1./255,
      validation_split=.75
      #rotation_range=40,
      #width_shift_range=0.2,
      #height_shift_range=0.2,
      #shear_range=0.2,
      #zoom_range=0.2,
      #horizontal_flip=True,
      #fill_mode='nearest'
      )

# validation split allows us to use 25% of the specified dir. for validation
validation_datagen = ImageDataGenerator(
      rescale=1./255,
      validation_split=.25
      #rotation_range=40,
      #width_shift_range=0.2,
      #height_shift_range=0.2,
      #shear_range=0.2,
      #zoom_range=0.2,
      #horizontal_flip=True,
      #fill_mode='nearest'
      )

# ResNet50

# training images
train_generator = train_datagen.flow_from_directory(
        '/tmp/data/vehicle_data/data/training/',
        target_size=(224, 224),
        subset='training',
        class_mode='sparse')

# validation images
validation_generator = validation_datagen.flow_from_directory(
        '/tmp/data/vehicle_data/data/test/',
        target_size=(224, 224),
        subset='validation',
        class_mode='sparse')

! ls /tmp/data/vehicle_data/data/test/non-vehicles/ | wc -l
! ls /tmp/data/vehicle_data/data/test/vehicles/ | wc -l



"""#Define and Train Model

## ResNet 50

Transfer learning was done with ResNet50, which is a convolutional neural netwrok with 50 layers.
"""

import tensorflow_hub as hub
import tensorflow_datasets as tfds

from tensorflow.keras.applications import ResNet50

IMAGE_SHAPE = (96,96)
#Using ResNet50 as our base model
base_model = ResNet50(weights="imagenet", include_top=False, input_shape=IMAGE_SHAPE+(3,))
base_model.trainable = False


model = tf.keras.Sequential([
        base_model,
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(10, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
])

model.summary()

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),
              metrics=['acc'])

model.fit(
      train_generator,
      epochs=10,
      validation_data=validation_generator)

"""###Save model

This line of code saves the model so we don't have to repeat training multiple times.
"""

resnet50_saved_model = "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/resnet50_saved_model"
tf.saved_model.save(model,resnet50_saved_model)

"""### Training Accuracy

Plots of training and validation accuracy.
"""

import matplotlib.pyplot as plt

history = model.history
# Get the training and validation accuracy from the history object
train_accuracy = history.history['acc']
validation_accuracy = history.history['val_acc']

# Plot the training and validation accuracy
plt.plot(train_accuracy, label='Training Accuracy')
plt.plot(validation_accuracy, label='Validation Accuracy')

# Set the title and labels
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

# Show the plot
plt.legend()
plt.show()

"""### Testing

We used another data generator to test the accuracy of the model. This generator only uses 10% of our test dataset.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

test_datagen = ImageDataGenerator(
      rescale=1/255.0,
      validation_split=.0974
      #rotation_range=40,
      #width_shift_range=0.2,
      #height_shift_range=0.2,
      #shear_range=0.2,
      #zoom_range=0.2,
      #horizontal_flip=True,
      #fill_mode='nearest'
      )

test_generator = test_datagen.flow_from_directory(
        '/tmp/data/vehicle_data/data/test/',
        target_size=(96, 96),
        batch_size=32,
        subset='validation',
        class_mode='categorical')

test_images=np.concatenate([test_generator.next()[0] for i in range(test_generator.__len__())])
test_labels=np.concatenate([test_generator.next()[1] for i in range(test_generator.__len__())])
print(test_images.shape)
print(test_labels.shape)

plt.imshow(test_images[30])

import math

predictions = model.predict_on_batch(test_images)
correct = 0

for i in range(len(predictions)):
  pred = predictions[i][0]
  if pred > 0.5:
    if math.ceil(pred) == test_labels[i]:
      correct += 1
  elif math.floor(pred) == test_labels[i]:
    correct += 1

print(f"Correct predictions: {correct} / {len(predictions)}")
print(f"Accuracy: {correct/len(predictions)}")

"""###Convert Model

The TFLiteConverter converts the saved tensorflow model into a light weight version that can be deployed on edge devices.
"""

#Converter quantization and optimized for size
import pathlib

converter = tf.lite.TFLiteConverter.from_saved_model(resnet50_saved_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_models_dir = pathlib.Path("/tmp/")
tflite_model = converter.convert()
tflite_model_file = tflite_models_dir/'resnet50_parksense.tflite'
tflite_model_file.write_bytes(tflite_model)

"""## MobileNet v2

Transfer learning was done with MobileNet v2, which is a 53 layer deep convolutional neural network.
"""

import tensorflow_hub as hub
import tensorflow_datasets as tfds
from tensorflow.keras.optimizers import RMSprop

module_selection = ("mobilenet_v2", 96, 1280)       # (pre-trained model, input pixel size, output feature vector size)
handle_base, pixels, FV_SIZE = module_selection
MODULE_HANDLE ="https://tfhub.dev/google/tf2-preview/{}/feature_vector/4".format(handle_base)
IMAGE_SIZE = (pixels, pixels)

MODULE_HANDLE ="https://tfhub.dev/google/imagenet/mobilenet_v2_035_96/feature_vector/5"
IMAGE_SHAPE = (96,96)

print("Using {} with input size {} ".format(MODULE_HANDLE, IMAGE_SHAPE))

base_model = hub.KerasLayer(MODULE_HANDLE,
                                   input_shape=IMAGE_SIZE + (3,),
                                   output_shape=[1280],
                                   trainable=False)

model = tf.keras.Sequential([
        base_model,
        tf.keras.layers.Dense(2, activation='softmax')
])

print("Building model with", MODULE_HANDLE)


model.summary()

model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam',
              metrics=['acc'])

history = model.fit(
      train_generator,
      epochs=5,
      validation_data=validation_generator)

mobilenetv2_saved_model = "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/mobilenetv2_0207"
tf.saved_model.save(model,mobilenetv2_saved_model)

"""### Training Accuracy"""

import matplotlib.pyplot as plt

history = model.history
# Get the training and validation accuracy from the history object
train_accuracy = history.history['acc']
validation_accuracy = history.history['val_acc']

# Plot the training and validation accuracy
plt.plot(train_accuracy, label='Training Accuracy')
plt.plot(validation_accuracy, label='Validation Accuracy')

# Set the title and labels
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

# Show the plot
plt.legend()
plt.show()

"""### Testing

"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

test_datagen = ImageDataGenerator(
      rescale=1./255,
      validation_split=.1035
      #rotation_range=40,
      #width_shift_range=0.2,
      #height_shift_range=0.2,
      #shear_range=0.2,
      #zoom_range=0.2,
      #horizontal_flip=True,
      #fill_mode='nearest'
      )

test_generator = test_datagen.flow_from_directory(
        '/tmp/data/vehicle_data/data/test/',
        target_size=(96, 96),
        batch_size=1,
        subset='validation',
        class_mode='sparse')

test_images=np.concatenate([test_generator.next()[0] for i in range(test_generator.__len__())])
test_labels=np.concatenate([test_generator.next()[1] for i in range(test_generator.__len__())])
test_labels = np.array([int(label) for label in test_labels])
print(test_images.shape)
print(test_labels.shape)

plt.imshow(test_images[2])

import math

predictions = model.predict_on_batch(test_images)
correct = 0

for i in range(len(predictions)):
  pred = predictions[i][0]
  #print(f"{i}, {pred}")
  if pred > 0.5:
    correct += 1
  # else:
  #   print(f"Incorrect: {i}")


print(f"Correct predictions: {correct} / {len(predictions)}")
print(f"Accuracy: {correct/len(predictions)}")

"""### Convert Model

#### Convert with default Optimizations
"""

#Converter quantization and optimized for size
import pathlib

saved_model = "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/mobilenetv2_0207"
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
]


tflite_models_dir = pathlib.Path("/content/drive/MyDrive/Colab Notebooks/ParkSense/models/")
tflite_model = converter.convert()
tflite_model_file = tflite_models_dir/'mobilenetv2_saved_model.tflite'
tflite_model_file.write_bytes(tflite_model)

"""#### Convert with Int8 Quantizations"""

test_dataset = tf.data.Dataset.from_generator(
    lambda: test_generator ,  # Our generator
    output_types = (tf.float32 , tf.int8) , # How we're expecting our output dtype
    output_shapes = ([1 , 96 , 96 , 3] , [1 , ]) # How we're expecting our output shape
)

saved_model = "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/mobilenetv2_0207"
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]    # optimization

def representative_data_gen():                          # quantization from representative dataset
    for input_value, _ in test_dataset.take(100):
        yield [input_value]

converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

tflite_model = converter.convert()
tflite_models_dir = pathlib.Path("/content/drive/MyDrive/Colab Notebooks/ParkSense/models/")

tflite_model_file = tflite_models_dir/'mobilenet_v2_saved_model_int8.tflite'
tflite_model_file.write_bytes(tflite_model)

"""### Normal Quant"""

! apt-get -qq install xxd
! xxd -i "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/mobilenetv2_saved_model.tflite" | sed "s/unsigned/const unsigned/g" > "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/model.h"

"""### Int8 Quant"""

! apt-get -qq install xxd
! xxd -i "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/mobilenet_v2_saved_model_int8.tflite" | sed "s/unsigned/const unsigned/g" > "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/model.h"

"""### Testing with camera output

"""

import numpy as np
from google.colab import files
# from keras.preprocessing import image
import keras.utils as image
import os

PATH='/content/drive/MyDrive/Colab Notebooks/ParkSense/data/test_data/'
test_images = os.listdir(PATH)

for fi in test_images:  # predicting images
  path = PATH + fi
  img = image.load_img(path, target_size=(96,96))
  x = image.img_to_array(img)
  x = x / 255.0
  x = np.expand_dims(x, axis=0)

  plt.imshow(img)
  image_tensor = np.vstack([x])
  classes = model.predict(image_tensor)
  print(classes[0])
  print()
  if classes[0][1]>0.5:
    print(fi + " is a car!")
  else:
    print(fi + " is not a car!")
  print('')

from tqdm import tqdm

# Load TFLite model and allocate tensors.
#tflite_model_file = '/content/drive/MyDrive/Colab Notebooks/ParkSense/models/mobilenetv2_saved_model.tflite'
tflite_model_file = '/content/drive/MyDrive/Colab Notebooks/ParkSense/models/mobilenet_v2_saved_model_int8.tflite'
interpreter = tf.lite.Interpreter(model_path=tflite_model_file)
interpreter.allocate_tensors()

input_index = interpreter.get_input_details()[0]["index"]
output_index = interpreter.get_output_details()[0]["index"]
predictions = []
test_labels, test_imgs = [], []
for img, label in tqdm(test_dataset.take(100)):
    interpreter.set_tensor(input_index, img)
    interpreter.invoke()
    predictions.append(interpreter.get_tensor(output_index))
    test_labels.append(label.numpy()[0])
    test_imgs.append(img)

score = 0
for item in range(0,100):
  prediction=np.argmax(predictions[item])
  label = test_labels[item]
  if prediction==label:
    score=score+1

print()
print("Out of 100 predictions I got " + str(score) + " correct")

"""#MobileNet v1

"""

import tensorflow_hub as hub
import tensorflow_datasets as tfds
from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.optimizers import RMSprop

# MODULE_HANDLE ="https://tfhub.dev/google/imagenet/mobilenet_v2_035_96/feature_vector/5"
IMAGE_SHAPE = (96,96)

# print("Using {} with input size {} ".format(MODULE_HANDLE, IMAGE_SHAPE))

base_model = MobileNet(input_shape=IMAGE_SHAPE+(3,),
                         alpha=0.35)

model = tf.keras.Sequential([
        base_model,
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(5, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
])

print("Building model with", MODULE_HANDLE)


model.summary()

model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(learning_rate=0.0001),
              metrics=['acc'])

"""# FOMO

https://docs.edgeimpulse.com/docs/edge-impulse-studio/learning-blocks/object-detection/fomo-object-detection-for-constrained-devices
"""

import tensorflow_hub as hub
import tensorflow_datasets as tfds
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2
from tensorflow.keras.layers import Conv2D, Dense, Flatten, GlobalAveragePooling2D
from tensorflow.keras import Model

MODULE_HANDLE ="https://tfhub.dev/google/imagenet/mobilenet_v2_035_96/feature_vector/5"
IMAGE_SIZE = (96, 96)

print("Using {} with input size {} ".format(MODULE_HANDLE, IMAGE_SIZE))

base_model = MobileNetV2(input_shape=IMAGE_SIZE + (3,), weights='imagenet', include_top=False)
base_model.trainable = False
cut_point = base_model.get_layer("block_6_expand_relu")

#in_conv = Conv2D(filters=32, kernel_size=1, strides=1, activation="relu", name="head")(cut_point.output)
#out_conv = Conv2D(filters=16, kernel_size=1, strides=1, activation="relu", name='out_conv')(in_conv)
gap = GlobalAveragePooling2D()(cut_point.output)
flatten = Flatten()(gap)
logits = Dense(2, name='logits_1', activation="softmax")(flatten)

model = Model(inputs=base_model.input, outputs=logits)

model.summary()
logits.shape

model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(
      train_generator,
      epochs=5,
      validation_data=validation_generator)

"""#Our Own Model

##Training
#####We decided to trian our own model in the hopes of decreasing the total model size due to storage limitations
"""

import tensorflow_hub as hub
import tensorflow_datasets as tfds
from tensorflow.keras.optimizers import RMSprop

IMAGE_SIZE = (96,96)

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=IMAGE_SIZE + (3,)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    #tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(4, activation='relu'),
    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.summary()

model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(learning_rate=0.0001),
              metrics=['acc'])

"""Fit model to data using data generators"""

history = model.fit(
      train_generator,
      epochs=5,
      validation_data=validation_generator)

"""Save model"""

custom_saved_model = "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/custom_convs_saved_model"
tf.saved_model.save(model,custom_saved_model)

"""Plot Accuracy"""

import matplotlib.pyplot as plt

history = model.history
# Get the training and validation accuracy from the history object
train_accuracy = history.history['acc']
validation_accuracy = history.history['val_acc']

# Plot the training and validation accuracy
plt.plot(train_accuracy, label='Training Accuracy')
plt.plot(validation_accuracy, label='Validation Accuracy')

# Set the title and labels
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

# Show the plot
plt.legend()
plt.show()

"""###Testing"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

test_datagen = ImageDataGenerator(
      rescale=1./255,
      validation_split=.1
      #rotation_range=40,
      #width_shift_range=0.2,
      #height_shift_range=0.2,
      #shear_range=0.2,
      #zoom_range=0.2,
      #horizontal_flip=True,
      #fill_mode='nearest'
      )

test_generator = test_datagen.flow_from_directory(
        '/tmp/data/stanford_cars/cars_test/',
        target_size=(96, 96),
        batch_size=32,
        subset='validation',
        class_mode='binary')

test_images=np.concatenate([test_generator.next()[0] for i in range(test_generator.__len__())])
test_labels=np.concatenate([test_generator.next()[1] for i in range(test_generator.__len__())])
print(test_images.shape)
print(test_labels.shape)

plt.imshow(test_images[90])

import math

predictions = model.predict_on_batch(test_images)
correct = 0

for i in range(len(predictions)):
  pred = predictions[i][0]
  #print(f"{i}, {pred}")
  if pred > 0.5:
    correct += 1
  # else:
  #   print(f"Incorrect: {i}")


print(f"Correct predictions: {correct} / {len(predictions)}")
print(f"Accuracy: {correct/len(predictions)}")

"""##Convert"""

#Converter quantization and optimized for size
import pathlib

saved_model = "/content/drive/MyDrive/Colab Notebooks/ParkSense/models/custom_convs_saved_model"
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]


tflite_models_dir = pathlib.Path("/tmp/")
tflite_model = converter.convert()
tflite_model_file = tflite_models_dir/'custom_convs_saved_model_defaultopt.tflite'
tflite_model_file.write_bytes(tflite_model)

"""###Optimize using int8"""

test_dataset = tf.data.Dataset.from_generator(
    lambda: test_generator ,  # Our generator
    output_types = (tf.float32 , tf.float32) , # How we're expecting our output dtype
    output_shapes = ([32 , 96 , 96 , 3] , [32 , ]) # How we're expecting our output shape
)


converter.optimizations = [tf.lite.Optimize.DEFAULT]    # optimization

def representative_data_gen():                          # quantization from representative dataset
    for input_value, _ in test_dataset.take(100):
        yield [input_value]

converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

tflite_model = converter.convert()
tflite_models_dir = pathlib.Path("/content/")

tflite_model_file = tflite_models_dir/'custom_convs_saved_model_int8.tflite'
tflite_model_file.write_bytes(tflite_model)

"""###Hexdump model for deployement"""

! apt-get -qq install xxd
! xxd -i "/content/custom_convs_saved_model_int8.tflite" | sed "s/unsigned/const unsigned/g" > "./model.h"

import numpy as np
from google.colab import files
# from keras.preprocessing import image
import keras.utils as image
import os

PATH='/content/drive/MyDrive/Colab Notebooks/ParkSense/data/test_data/'
test_images = os.listdir(PATH)

for fi in test_images:  # predicting images
  path = PATH + fi
  img = image.load_img(path, target_size=(96,96))
  x = image.img_to_array(img)
  x = x / 255.0
  x = np.expand_dims(x, axis=0)

  plt.imshow(img)
  image_tensor = np.vstack([x])
  classes = model.predict(image_tensor)
  print(classes[0])
  print()
  if classes[0]>0.5:
    print(fi + " is a car!")
  else:
    print(fi + " is not a car!")
  print('')